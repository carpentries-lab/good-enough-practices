---
title: "Conclusion"
teaching: 0
exercises: 0
questions:
- ""
- ""
- ""
objectives:
- ""
- ""
- ""
keypoints:
- ""
- ""
- ""
---

## Ten simple rules for reproducible computational research

- Keep Track of How Every Result Was Produced
- Avoid Manual Data Manipulation Steps
- Track Versions of All External Programs Used
- Version Control Your Protocols/Scripts
- Record All Intermediate Results
- Track Relevant Sources of Randomness
- Store Raw Data behind Plots
- Allow Layers of Detail to Be Inspected
- Connect Statements to Underlying Results
- Share Scripts, Runs, and Results

After [Geir Kjetil Sandve et al (2013)](https://doi.org/10.1371/journal.pcbi.1003285)


> Heads up
>
> When you lose your data, or stare, disgusted, at a horrible file, think of today.
>
{: .callout}


## Conclusion

We have outlined a series of practices for scientific computing based on
our collective experience, and the experience of the thousands of
researchers we have met through Software Carpentry, Data Carpentry, and
similar organizations. These practices are pragmatic, accessible to
people who consider themselves new to computing, and can be applied by
both individuals and groups. Most importantly, these practices make
researchers more productive individually by enabling them to get more
done in less time and with less pain. They also accelerate research as a
whole by making computational work (which increasingly means *all* work)
more reproducible.

But progress will not happen by itself. The practices are being
increasingly incentivized through requirements from funding agencies and
journals, but the time and skills required to put these approaches into
practice are still not being valued.

At a local level, PIs can have the most impact, requiring that the
research their lab produces follow these recommendations. Even if a PI
doesn't have a background in computation, they can require that students
show and share their code in lab meetings and with lab mates, that data
is available and accessible to all in the lab and that computational
methods sections are comprehensive. PIs can also value the time it takes
to do these things effectively and provide opportunities for training.

Universities can also support such efforts. While this is often provided
by IT or High Performance Computing (HPC) groups, research librarians
are an often under-appreciated resource. Librarians have thought about
and worked with data and provenance even before these computational
challenges and increasingly have dedicated data librarians on staff who
have an explicit service role.

Many campuses also have self-organized groups led by students who wish
to learn from each other, which may operate independently or in concert
with organizations like Software Carpentry, Data Carpentry, or
The Hacker Within[^38].

Finally, many funding agencies now require data management plans and
education and outreach activities. The true cost of implementing these
plans includes training: it is unfair as well as counter-productive to
insist that researchers do things without teaching them how. We believe
it is now time for funders to invest in such training; we hope that our
recommendations will help shape consensus on what "good enough" looks
like and how to achieve it.


> ## Attribution
> Content of this episode was adopted after Wilson et al.
> [Good Enough Practices for Scientific Computing](https://github.com/swcarpentry/good-enough-practices-in-scientific-computing).
{: .callout}


{% include links.md %}

